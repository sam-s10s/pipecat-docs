---
title: "LMNT"
description: "Text-to-speech service implementation using LMNTâ€™s streaming API"
---

## Overview

LMNT provides real-time text-to-speech synthesis through a WebSocket-based streaming API optimized for conversational AI. The service offers ultra-low latency with high-quality voice models and supports multiple languages with automatic interruption handling.

<CardGroup cols={3}>
  <Card
    title="API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.lmnt.tts.html"
  >
    Complete API documentation and method details
  </Card>
  <Card
    title="LMNT Speech Docs"
    icon="book"
    href="https://docs.lmnt.com/api-reference/speech/streaming"
  >
    Official LMNT streaming speech API documentation
  </Card>
  <Card
    title="Example Code"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07k-interruptible-lmnt.py"
  >
    Working example with voice synthesis
  </Card>
</CardGroup>

## Installation

To use LMNT services, install the required dependencies:

```bash
pip install "pipecat-ai[lmnt]"
```

You'll also need to set up your LMNT API key as an environment variable: `LMNT_API_KEY`.

<Tip>Get your API key from the [LMNT Console](https://app.lmnt.com/).</Tip>

## Frames

### Input

- `TextFrame` - Text content to synthesize into speech
- `TTSSpeakFrame` - Text that should be spoken immediately
- `TTSUpdateSettingsFrame` - Runtime configuration updates
- `LLMFullResponseStartFrame` / `LLMFullResponseEndFrame` - LLM response boundaries

### Output

- `TTSStartedFrame` - Signals start of synthesis
- `TTSAudioRawFrame` - Generated audio data chunks (streaming PCM)
- `TTSStoppedFrame` - Signals completion of synthesis
- `ErrorFrame` - WebSocket or API errors

## Language Support

<Accordion title="View All Supported Languages">

| Language Code | Description | Service Code |
| ------------- | ----------- | ------------ |
| `Language.DE` | German      | `de`         |
| `Language.EN` | English     | `en`         |
| `Language.ES` | Spanish     | `es`         |
| `Language.FR` | French      | `fr`         |
| `Language.HI` | Hindi       | `hi`         |
| `Language.ID` | Indonesian  | `id`         |
| `Language.IT` | Italian     | `it`         |
| `Language.JA` | Japanese    | `ja`         |
| `Language.KO` | Korean      | `ko`         |
| `Language.NL` | Dutch       | `nl`         |
| `Language.PL` | Polish      | `pl`         |
| `Language.PT` | Portuguese  | `pt`         |
| `Language.RU` | Russian     | `ru`         |
| `Language.SV` | Swedish     | `sv`         |
| `Language.TH` | Thai        | `th`         |
| `Language.TR` | Turkish     | `tr`         |
| `Language.UK` | Ukrainian   | `uk`         |
| `Language.VI` | Vietnamese  | `vi`         |
| `Language.ZH` | Chinese     | `zh`         |

</Accordion>

Most common languages supported:

- `Language.EN` - English
- `Language.ES` - Spanish
- `Language.FR` - French
- `Language.DE` - German
- `Language.ZH` - Chinese
- `Language.JA` - Japanese

## Usage Example

### Basic Configuration

Initialize the `LmntTTSService` and use it in a pipeline:

```python
from pipecat.services.lmnt.tts import LmntTTSService
from pipecat.transcriptions.language import Language
import os

# Configure service
tts = LmntTTSService(
    api_key=os.getenv("LMNT_API_KEY"),
    voice_id="morgan",
    model="aurora",
    language=Language.EN,
    sample_rate=24000
)

# Use in pipeline
pipeline = Pipeline([
    transport.input(),
    stt,
    context_aggregator.user(),
    llm,
    tts,
    transport.output(),
    context_aggregator.assistant()
])
```

### Dynamic Configuration

Make settings updates by pushing a `TTSUpdateSettingsFrame` for the `LmntTTSService`:

```python
from pipecat.frames.frames import TTSUpdateSettingsFrame

await task.queue_frame(
    TTSUpdateSettingsFrame(settings={"voice": "your-new-voice-id"})
)
```

## Metrics

The service provides real-time metrics:

- **Time to First Byte (TTFB)** - Latency from text input to first audio
- **Processing Duration** - Total synthesis time
- **Character Usage** - Text processed for billing

<Info>
  [Learn how to enable Metrics](/guides/fundamentals/metrics) in your Pipeline.
</Info>

## Additional Notes

- **WebSocket Streaming**: Uses persistent WebSocket connection for ultra-low latency
- **Custom Voices**: Supports custom voice creation through LMNT dashboard
- **Language Detection**: Automatically handles language variants and fallbacks
