---
title: "Cartesia"
description: "Text-to-speech services using Cartesia‚Äôs WebSocket and HTTP APIs"
---

## Overview

Cartesia provides two TTS service implementations:

- `CartesiaTTSService`: WebSocket-based with streaming and word timestamps
- `CartesiaHttpTTSService`: HTTP-based for simpler synthesis

<Tip>`CartesiaTTSService` is recommended for real-time applications.</Tip>

<CardGroup cols={3}>
  <Card
    title="API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.cartesia.tts.html"
  >
    Complete API documentation and method details
  </Card>
  <Card
    title="Cartesia Docs"
    icon="book"
    href="https://docs.cartesia.ai/2024-11-13/get-started/overview"
  >
    Official Cartesia documentation and features
  </Card>
  <Card
    title="Example Code"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07-interruptible.py"
  >
    Working example with interruption handling
  </Card>
</CardGroup>

## Installation

To use Cartesia services, install the required dependencies:

```bash
pip install "pipecat-ai[cartesia]"
```

You'll also need to set up your Cartesia API key as an environment variable: `CARTESIA_API_KEY`.

<Tip>
  Get your API key by signing up at
  [Cartesia](https://play.cartesia.ai/sign-up).
</Tip>

## Frames

### Input

- `TextFrame` - Text content to synthesize into speech
- `TTSSpeakFrame` - Text that the TTS service should speak
- `TTSUpdateSettingsFrame` - Runtime configuration updates (e.g., voice)
- `LLMFullResponseStartFrame` / `LLMFullResponseEndFrame` - LLM response boundaries

### Output

- `TTSStartedFrame` - Signals start of synthesis
- `TTSAudioRawFrame` - Generated audio data chunks
- `TTSStoppedFrame` - Signals completion of synthesis
- `ErrorFrame` - Connection or processing errors

## Service Comparison

| Feature             | CartesiaTTSService (WebSocket) | CartesiaHttpTTSService (HTTP) |
| ------------------- | ------------------------------ | ----------------------------- |
| **Streaming**       | ‚úÖ Real-time chunks            | ‚ùå Single audio block         |
| **Word Timestamps** | ‚úÖ Precise timing              | ‚ùå Not available              |
| **Interruption**    | ‚úÖ Advanced handling           | ‚ö†Ô∏è Basic support              |
| **Latency**         | üöÄ Low                         | üìà Higher                     |
| **Best For**        | Interactive apps               | Batch processing              |

## Language Support

Supports multiple languages through the `Language` enum:

| Language Code | Description        | Service Code |
| ------------- | ------------------ | ------------ |
| `Language.DE` | German             | `de`         |
| `Language.EN` | English            | `en`         |
| `Language.ES` | Spanish            | `es`         |
| `Language.FR` | French             | `fr`         |
| `Language.HI` | Hindi              | `hi`         |
| `Language.IT` | Italian            | `it`         |
| `Language.JA` | Japanese           | `ja`         |
| `Language.KO` | Korean             | `ko`         |
| `Language.NL` | Dutch              | `nl`         |
| `Language.PL` | Polish             | `pl`         |
| `Language.PT` | Portuguese         | `pt`         |
| `Language.RU` | Russian            | `ru`         |
| `Language.SV` | Swedish            | `sv`         |
| `Language.TR` | Turkish            | `tr`         |
| `Language.ZH` | Chinese (Mandarin) | `zh`         |

## Usage Example

### WebSocket Service (Recommended)

Initialize the WebSocket service with your API key and desired voice:

```python
from pipecat.services.cartesia.tts import CartesiaTTSService
from pipecat.transcriptions.language import Language
import os

# Configure WebSocket service
tts = CartesiaTTSService(
    api_key=os.getenv("CARTESIA_API_KEY"),
    voice_id="your-voice-id",
    model="sonic-2",
    params=CartesiaTTSService.InputParams(
        language=Language.EN,
        speed="normal"
    )
)

# Use in pipeline
pipeline = Pipeline([
    transport.input(),
    stt,
    llm,
    tts,  # Word timestamps enable precise context updates
    transport.output()
])
```

### HTTP Service

Initialize the HTTP service and use it in a pipeline:

```python
# For simpler, non-streaming use cases
http_tts = CartesiaHttpTTSService(
    api_key=os.getenv("CARTESIA_API_KEY"),
    voice_id="your-voice-id",
    model="sonic-2",
    params=CartesiaHttpTTSService.InputParams(
        language=Language.EN
    )
)
```

### Dynamic Configuration

Make settings updates by pushing a `TTSUpdateSettingsFrame` for the `CartesiaTTSService`:

```python
from pipecat.frames.frames import TTSUpdateSettingsFrame

await task.queue_frame(
    TTSUpdateSettingsFrame(settings={"voice": "your-new-voice-id"})
)
```

## Metrics

Both services provide:

- **Time to First Byte (TTFB)** - Latency from text input to first audio
- **Processing Duration** - Total synthesis time
- **Usage Metrics** - Character count and synthesis statistics

<Info>
  [Learn how to enable Metrics](/guides/fundamentals/metrics) in your Pipeline.
</Info>

## Additional Notes

- **WebSocket Recommended**: Use `CartesiaTTSService` for low-latency streaming and accurate context updates with word timestamps
- **Connection Management**: WebSocket lifecycle is handled automatically with reconnection support
- **Sample Rate**: Set globally in `PipelineParams` rather than per-service for consistency
