---
title: "AWS Nova Sonic"
description: "Real-time speech-to-speech service implementation using AWS Nova Sonic"
---

The `AWSNovaSonicLLMService` enables natural, real-time conversations with AWS Nova Sonic. It provides built-in audio transcription, voice activity detection, and context management for creating interactive AI experiences. It provides:

<CardGroup cols={2}>
  <Card title="Real-time Interaction" icon="bolt">
    Stream audio in real-time with low latency response times
  </Card>

{" "}

<Card title="Speech Processing" icon="waveform-lines">
  Built-in speech-to-text and text-to-speech capabilities with multiple voice
  options
</Card>

{" "}

<Card title="Voice Activity Detection" icon="microphone">
  Automatic detection of speech start/stop for natural conversations
</Card>

  <Card title="Context Management" icon="brain">
    Intelligent handling of conversation history and system instructions
  </Card>
</CardGroup>

## Installation

To use `AWSNovaSonicLLMService`, install the required dependencies:

```bash
pip install "pipecat-ai[aws-nova-sonic]"
```

We recommend setting up your AWS credentials as environment variables, as you'll need them to initialize `AWSNovaSonicLLMService`:

- `AWS_SECRET_ACCESS_KEY`
- `AWS_ACCESS_KEY_ID`
- `AWS_REGION`

## Basic Usage

Hereâ€™s a simple example of setting up a conversational AI bot with AWS Nova Sonic:

```python
from pipecat.services.aws_nova_sonic.aws import AWSNovaSonicLLMService

llm = AWSNovaSonicLLMService(
    secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
    access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
    region=os.getenv("AWS_REGION")
    voice_id="tiffany",                    # Voices: matthew, tiffany, amy
)
```

## Configuration

### Constructor Parameters

<ParamField path="secret_access_key" type="str" required>
  Your AWS secret access key
</ParamField>

<ParamField path="access_key_id" type="str" required>
  Your AWS access key ID
</ParamField>

<ParamField path="region" type="str" required>
  Specify the AWS region for the service (e.g., `"us-east-1"`). Note that the
  service may not be available in all AWS regions: check the [AWS Bedrock User
  Guide's support
  table](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html).
</ParamField>

<ParamField path="model" type="str" default="amazon.nova-sonic-v1:0">
  AWS Nova Sonic model to use. Note that `"amazon.nova-sonic-v1:0"` is the only
  supported model as of 2025-05-08.
</ParamField>

<ParamField path="voice_id" type="str" default="matthew">
  Voice for text-to-speech (options: `"matthew"`, `"tiffany"`, `"amy"`)
</ParamField>

<ParamField path="params" type="Params" optional>
  Configuration for model parameters
</ParamField>

<ParamField path="system_instruction" type="str" optional>
  High-level instructions that guide the model's behavior. Note that more
  commonly these instructions will be included as part of the context provided
  to kick off the conversation.
</ParamField>

<ParamField path="tools" type="ToolsSchema" optional>
  List of function definitions for tool/function calling. Note that more
  commonly tools will be included as part of the context provided to kick off
  the conversation.
</ParamField>

<ParamField path="send_transcription_frames" type="bool" default="True">
  Whether to emit transcription frames
</ParamField>

### Model Parameters

The `Params` object configures the behavior of the AWS Nova Sonic model.

<Warning>
  It is strongly recommended to stick with default values (most easily by
  omitting `params` when constructing `AWSNovaSonicLLMService`) unless you have
  a good understanding of the parameters and their impact. Deviating from the
  defaults may lead to unexpected behavior.
</Warning>

<ParamField path="temperature" type="float" optional default="0.7">
  Controls randomness in responses. Range: 0.0 to 2.0
</ParamField>

<ParamField path="max_tokens" type="int" optional default="1024">
  Maximum number of tokens to generate
</ParamField>

<ParamField path="top_p" type="float" optional default="0.9">
  Cumulative probability cutoff for token selection. Range: 0.0 to 1.0
</ParamField>

<ParamField path="input_sample_rate" type="int" optional default="16000">
  Sample rate for input audio
</ParamField>

<ParamField path="output_sample_rate" type="int" optional default="24000">
  Sample rate for output audio
</ParamField>

<ParamField path="input_sample_size" type="int" optional default="16">
  Bit depth for input audio
</ParamField>

<ParamField path="input_channel_count" type="int" optional default="1">
  Number of channels for input audio
</ParamField>

<ParamField path="output_sample_size" type="int" optional default="16">
  Bit depth for output audio
</ParamField>

<ParamField path="output_channel_count" type="int" optional default="1">
  Number of channels for output audio
</ParamField>

## Frame Types

### Input Frames

<ParamField path="InputAudioRawFrame" type="Frame">
  Raw audio data for speech input
</ParamField>

<ParamField path="OpenAILLMContextFrame" type="Frame">
  Contains conversation context
</ParamField>

<ParamField path="BotStoppedSpeakingFrame" type="Frame">
  Signals the bot has stopped speaking
</ParamField>

### Output Frames

<ParamField path="TTSAudioRawFrame" type="Frame">
  Generated speech audio
</ParamField>

<ParamField path="LLMFullResponseStartFrame" type="Frame">
  Signals the start of a response from the LLM
</ParamField>

<ParamField path="LLMFullResponseEndFrame" type="Frame">
  Signals the end of a response from the LLM
</ParamField>

<ParamField path="TTSStartedFrame" type="Frame">
  Signals start of speech synthesis (coincides with the start of the LLM
  response, as this is a speech-to-speech model)
</ParamField>

<ParamField path="TTSStoppedFrame" type="Frame">
  Signals end of speech synthesis (coincides with the end of the LLM response,
  as this is a speech-to-speech model)
</ParamField>

<ParamField path="LLMTextFrame" type="Frame">
  Generated text responses from the LLM
</ParamField>

<ParamField path="TTSTextFrame" type="Frame">
  Generated text responses
</ParamField>

<ParamField path="TranscriptionFrame" type="Frame">
  Speech transcriptions. Only output if `send_transcription_frames` is `True`.
</ParamField>

## Function Calling

This service supports function calling (also known as tool calling) which allows the LLM to request information from external services and APIs. For example, you can enable your bot to:

- Check current weather conditions
- Query databases
- Access external APIs
- Perform custom actions

See the [Function Calling guide](/learn/function-calling) for:

- Detailed implementation instructions
- Provider-specific function definitions
- Handler registration examples
- Control over function call behavior
- Complete usage examples

## Next Steps

### Examples

- [Foundational Example](https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/40-aws-nova-sonic.py)
  Basic implementation showing core features

- [Persistent Content Example](https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/20e-persistent-context-aws-nova-sonic.py)
  Implementation showing saving and loading conversation history
